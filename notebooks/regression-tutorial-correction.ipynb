{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Valentin-Laurent/MAPIE-DataCraft/blob/main/notebooks/regression-tutorial-correction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "source": [
        "# Measuring Model Uncertainty in Regression with MAPIE\n",
        "---\n",
        "\n",
        "In this notebook, we will estimate prediction intervals with MAPIE.\n",
        "\n",
        "We will determine the validity of our prediction intervals using two metrics:\n",
        "\n",
        "- The \"effective\" coverage, which is the percentage of test data included in the prediction intervals. For example, for a target confidence level of 90%, 90% of the test data should be within the produced intervals.\n",
        "- The average width of the prediction intervals, which should be as close as possible to the \"theoretical\" width used to generate data noise."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/MAPIE-DataCraft\n",
        "!git clone https://github.com/Valentin-Laurent/MAPIE-DataCraft"
      ],
      "metadata": {
        "id": "sBcyzzY3Zfs2",
        "outputId": "e3024ae8-17d1-4c65-df39-8fe9b100f38c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sBcyzzY3Zfs2",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MAPIE-DataCraft'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 82 (delta 26), reused 82 (delta 26), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (82/82), 1.53 MiB | 8.30 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mapie"
      ],
      "metadata": {
        "id": "T_fgJIJWZt4X",
        "outputId": "2b734ef0-e6c7-4ae2-e5bd-95da11a22e83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "T_fgJIJWZt4X",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mapie\n",
            "  Downloading mapie-1.0.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.4 in /usr/local/lib/python3.11/dist-packages (from mapie) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mapie) (1.15.3)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from mapie) (2.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4->mapie) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4->mapie) (3.6.0)\n",
            "Downloading mapie-1.0.1-py3-none-any.whl (173 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mapie\n",
            "Successfully installed mapie-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1",
      "metadata": {
        "id": "1"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2",
      "metadata": {
        "id": "2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import sys\n",
        "\n",
        "sys.path.append('/content/MAPIE-DataCraft/notebooks/utils')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression, QuantileRegressor\n",
        "from mapie.metrics.regression import regression_coverage_score, regression_mean_width_score\n",
        "from mapie.regression import CrossConformalRegressor, ConformalizedQuantileRegressor\n",
        "\n",
        "from dataset import (\n",
        "    x_sinx,\n",
        "    get_1d_data_with_constant_noise,\n",
        "    get_1d_data_with_heteroscedastic_noise,\n",
        "    get_1d_data_with_normal_distribution,\n",
        ")\n",
        "from viz import (\n",
        "    plot_regression,\n",
        "    plot_uncertainties,\n",
        "    plot_prediction_interval_width,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3",
      "metadata": {
        "id": "3"
      },
      "source": [
        "# Uncertainty in Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4",
      "metadata": {
        "id": "4"
      },
      "source": [
        "## Homoscedastic Noise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5",
      "metadata": {
        "id": "5"
      },
      "source": [
        "Let's start by building an artificial dataset. We will use the function $f(x) = x\\sin(x)$ to which we add constant Gaussian noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6",
      "metadata": {
        "id": "6"
      },
      "outputs": [],
      "source": [
        "X, y, X_test, y_test, y_mesh = get_1d_data_with_constant_noise(\n",
        "    funct=x_sinx,\n",
        "    min_x=-5,\n",
        "    max_x=5,\n",
        "    n_samples=600,\n",
        "    noise=0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7",
      "metadata": {
        "id": "7"
      },
      "source": [
        "Let's visualize the dataset and its generating function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8",
      "metadata": {
        "id": "8"
      },
      "outputs": [],
      "source": [
        "plot_regression(\n",
        "    X_test,\n",
        "    y_test,\n",
        "    y_mesh,\n",
        "    name_mesh=\"Generator\",\n",
        "    title=\"Homoscedastic Problem\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9",
      "metadata": {
        "id": "9"
      },
      "source": [
        "We will learn a polynomial model to fit the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10",
      "metadata": {
        "id": "10"
      },
      "outputs": [],
      "source": [
        "polyn_model = Pipeline(\n",
        "    [\n",
        "        (\"poly\", PolynomialFeatures(degree=10)),\n",
        "        (\"linear\", LinearRegression())\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11",
      "metadata": {
        "id": "11"
      },
      "source": [
        "**Exercise 1**: We now want to train this model with MAPIE and obtain 95% confidence intervals.\n",
        "- Instantiate a `CrossConformalRegressor` wrapping our polynomial model with the CV+ method with 5 cross-validation folds, and a confidence level of 95%.\n",
        "- Train and conformalize the `CrossConformalRegressor` on the dataset.\n",
        "- Predict on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12",
      "metadata": {
        "id": "12"
      },
      "outputs": [],
      "source": [
        "mapie_regressor = CrossConformalRegressor(  # correction\n",
        "    estimator=polyn_model,  # correction\n",
        "    confidence_level=0.95,  # correction\n",
        "    cv=5,  # correction\n",
        "    method=\"plus\",  # correction\n",
        "    random_state=1  # correction\n",
        "    )  # correction\n",
        "mapie_regressor.fit_conformalize(X, y)  # correction\n",
        "y_preds, y_pred_intervals = mapie_regressor.predict_interval(X_test)  # correction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13",
      "metadata": {
        "id": "13"
      },
      "source": [
        "Let's visualize the prediction intervals obtained on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14",
      "metadata": {
        "id": "14"
      },
      "outputs": [],
      "source": [
        "plot_uncertainties(\n",
        "    X_test,\n",
        "    y_test,\n",
        "    y_preds,\n",
        "    y_pred_intervals,\n",
        "    title=\"Prediction Intervals with 95% Confidence Level\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15",
      "metadata": {
        "id": "15"
      },
      "source": [
        "Let's visualize the width of the prediction intervals as a function of $x$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16",
      "metadata": {
        "id": "16"
      },
      "outputs": [],
      "source": [
        "plot_prediction_interval_width(\n",
        "    X_test,\n",
        "    y_pred_intervals,\n",
        "    title=\"Width of Prediction Intervals\",\n",
        "    yaxis_title=\"Width\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17",
      "metadata": {
        "id": "17"
      },
      "source": [
        "Here we see that the confidence intervals are roughly constant, which is expected given the homoscedasticity of the problem!\n",
        "\n",
        "**Exercise 2**: calculate the uncertainty metrics:\n",
        "- Coverage rate (`regression_coverage_score`)\n",
        "- Average size of prediction intervals (`regression_mean_width_score`)\n",
        "- Did we achieve the target coverage rate of 95%?\n",
        "- The theoretical size of the intervals is `1.96`. Is the average size of the intervals predicted by MAPIE larger? Smaller?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18",
      "metadata": {
        "id": "18"
      },
      "outputs": [],
      "source": [
        "print(f\"Empirical coverage rate: {regression_coverage_score(y_test, y_pred_intervals)[0]:.3f}\")  # correction\n",
        "print(f\"Average interval width: {regression_mean_width_score(y_pred_intervals)[0]:.3f}\")  # correction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19",
      "metadata": {
        "id": "19"
      },
      "source": [
        "## Heteroscedastic Noise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20",
      "metadata": {
        "id": "20"
      },
      "source": [
        "Let's start by building an artificial dataset. We will use the function $f(x) = x\\sin(x)$ to which we add Gaussian noise proportional to $x$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21",
      "metadata": {
        "id": "21"
      },
      "outputs": [],
      "source": [
        "X, y, X_test, y_test, y_mesh = get_1d_data_with_heteroscedastic_noise(\n",
        "    funct=x_sinx,\n",
        "    min_x=0,\n",
        "    max_x=5,\n",
        "    n_samples=600,\n",
        "    noise=0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22",
      "metadata": {
        "id": "22"
      },
      "source": [
        "Let's visualize the dataset and its generating function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23",
      "metadata": {
        "id": "23"
      },
      "outputs": [],
      "source": [
        "plot_regression(\n",
        "    X_test,\n",
        "    y_test,\n",
        "    y_mesh,\n",
        "    name_mesh=\"Generator\",\n",
        "    title=\"Heteroscedastic Problem\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24",
      "metadata": {
        "id": "24"
      },
      "source": [
        "In this setting, using a `CrossConformalRegressor` would result in confidence intervals being roughly constant, even though the noise in the data is not at all!\n",
        "Fortunately, there is a solution to obtain adaptive prediction intervals: conformalized quantile regression. Let's first instantiate a quantile model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25",
      "metadata": {
        "id": "25"
      },
      "outputs": [],
      "source": [
        "polyn_model_quant = Pipeline(\n",
        "    [\n",
        "        (\"poly\", PolynomialFeatures(degree=10)),\n",
        "        (\"linear\", QuantileRegressor(solver=\"highs\", alpha=0))\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26",
      "metadata": {
        "id": "26"
      },
      "source": [
        "**Exercise 3**: We now want to train this model with MAPIE and obtain 95% confidence intervals.\n",
        "- Split the input data (`X` and `y`) into `X_train`, `X_conformalize`, `y_train`, `y_conformalize`\n",
        "- Instantiate a `ConformalizedQuantileRegressor` wrapping our polynomial model with a confidence level of 95%\n",
        "- Train the `MapieQuantileRegressor` on the training set, and conformalize it on the conformalization set\n",
        "- Predict on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27",
      "metadata": {
        "id": "27"
      },
      "outputs": [],
      "source": [
        "X_train, X_conformalize, y_train, y_conformalize = train_test_split(X, y)  # correction\n",
        "mapie_regressor = ConformalizedQuantileRegressor(estimator=polyn_model_quant, confidence_level=0.95)  # correction\n",
        "mapie_regressor.fit(X_train, y_train)  # correction\n",
        "mapie_regressor.conformalize(X_conformalize, y_conformalize)  # correction\n",
        "y_preds, y_pred_intervals = mapie_regressor.predict_interval(X_test)  # correction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28",
      "metadata": {
        "id": "28"
      },
      "source": [
        "Let's visualize the prediction intervals obtained on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29",
      "metadata": {
        "id": "29"
      },
      "outputs": [],
      "source": [
        "plot_uncertainties(\n",
        "    X_test,\n",
        "    y_test,\n",
        "    y_preds,\n",
        "    y_pred_intervals,\n",
        "    title=\"Prediction Intervals with 95% Confidence Level\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30",
      "metadata": {
        "id": "30"
      },
      "source": [
        "Let's visualize the width of the prediction intervals as a function of $x$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31",
      "metadata": {
        "id": "31"
      },
      "outputs": [],
      "source": [
        "plot_prediction_interval_width(\n",
        "    X_test,\n",
        "    y_pred_intervals,\n",
        "    title=\"Width of Prediction Intervals\",\n",
        "    yaxis_title=\"Width\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32",
      "metadata": {
        "id": "32"
      },
      "source": [
        "Ah, there it is! We have captured the heteroscedasticity well!\n",
        "\n",
        "**Exercise 4**: calculate the uncertainty metrics:\n",
        "- Coverage rate (`regression_coverage_score`)\n",
        "- Average size of prediction intervals (`regression_mean_width_score`)\n",
        "- Did we achieve the target coverage rate of 95%?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33",
      "metadata": {
        "id": "33"
      },
      "outputs": [],
      "source": [
        "print(f\"Empirical coverage rate: {regression_coverage_score(y_test, y_pred_intervals)[0]:.3f}\")  # correction\n",
        "print(f\"Average interval width: {regression_mean_width_score(y_pred_intervals)[0]:.3f}\")  # correction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34",
      "metadata": {
        "id": "34"
      },
      "source": [
        "Bingo! The coverage rate is still good, and the average size of our intervals is significantly lower than if we had used a `CrossConformalRegressor`!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35",
      "metadata": {
        "id": "35"
      },
      "source": [
        "## Epistemic Uncertainty"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36",
      "metadata": {
        "id": "36"
      },
      "source": [
        "Let's start by building an artificial dataset. We will use the function $f(x) = x\\sin(x)$ to which we add constant Gaussian noise, but with data points distributed non-uniformly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37",
      "metadata": {
        "id": "37"
      },
      "outputs": [],
      "source": [
        "X, y, X_test, y_test, y_mesh = get_1d_data_with_normal_distribution(\n",
        "    funct=x_sinx,\n",
        "    mu=0,\n",
        "    sigma=2,\n",
        "    n_samples=600,\n",
        "    noise=0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38",
      "metadata": {
        "id": "38"
      },
      "source": [
        "Let's visualize the dataset and its generating function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39",
      "metadata": {
        "id": "39"
      },
      "outputs": [],
      "source": [
        "plot_regression(\n",
        "    X_test,\n",
        "    y_test,\n",
        "    y_mesh,\n",
        "    name_mesh=\"Generator\",\n",
        "    title=\"Epistemic Problem\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40",
      "metadata": {
        "id": "40"
      },
      "source": [
        "**Exercise 5**: We now want to train this model with MAPIE and obtain 95% confidence intervals.\n",
        "- Split the input data (`X` and `y`) into `X_train`, `X_conformalize`, `y_train`, `y_conformalize`\n",
        "- Instantiate a `ConformalizedQuantileRegressor` wrapping our polynomial model with a confidence level of 95%\n",
        "- Train the `MapieQuantileRegressor` on the training set, and conformalize it on the conformalization set\n",
        "- Predict on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41",
      "metadata": {
        "id": "41"
      },
      "outputs": [],
      "source": [
        "X_train, X_conformalize, y_train, y_conformalize = train_test_split(X, y)  # correction\n",
        "mapie_regressor = ConformalizedQuantileRegressor(estimator=polyn_model_quant, confidence_level=0.95)  # correction\n",
        "mapie_regressor.fit(X_train, y_train)  # correction\n",
        "mapie_regressor.conformalize(X_conformalize, y_conformalize)  # correction\n",
        "y_preds, y_pred_intervals = mapie_regressor.predict_interval(X_test)  # correction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42",
      "metadata": {
        "id": "42"
      },
      "source": [
        "Let's visualize the prediction intervals obtained on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43",
      "metadata": {
        "id": "43"
      },
      "outputs": [],
      "source": [
        "plot_uncertainties(\n",
        "    X_test,\n",
        "    y_test,\n",
        "    y_preds,\n",
        "    y_pred_intervals,\n",
        "    title=\"Prediction Intervals with 95% Confidence Level\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44",
      "metadata": {
        "id": "44"
      },
      "source": [
        "Let's visualize the width of the prediction intervals as a function of $x$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45",
      "metadata": {
        "id": "45"
      },
      "outputs": [],
      "source": [
        "plot_prediction_interval_width(\n",
        "    X_test,\n",
        "    y_pred_intervals,\n",
        "    title=\"Width of Prediction Intervals\",\n",
        "    yaxis_title=\"Width\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46",
      "metadata": {
        "id": "46"
      },
      "source": [
        "We see that the confidence intervals explode when the density of the dataset decreases, capturing the epistemic error well!\n",
        "\n",
        "**Exercise 6**: calculate the uncertainty metrics:\n",
        "- Coverage rate (`regression_coverage_score`)\n",
        "- Average size of prediction intervals (`regression_mean_width_score`)\n",
        "- Did we achieve the target coverage rate of 95%?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47",
      "metadata": {
        "id": "47"
      },
      "outputs": [],
      "source": [
        "print(f\"Empirical coverage rate: {regression_coverage_score(y_test, y_pred_intervals)[0]:.3f}\")  # correction\n",
        "print(f\"Average interval width: {regression_mean_width_score(y_pred_intervals)[0]:.3f}\")  # correction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48",
      "metadata": {
        "id": "48"
      },
      "source": [
        "Congratulations, you have mastered uncertainties in regression with MAPIE!"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "formats": "ipynb,md"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}